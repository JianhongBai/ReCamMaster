<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="ReCamMaster: Camera-Controlled Generative Rendering from A Single Video">
  <meta property="og:title" content="ReCamMaster" />
  <meta property="og:description" content="Recapture your videos with novel camera trajectories!" />
  <meta property="og:url" content="URL OF THE WEBSITE" />
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="pics/icon.png" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />


  <meta name="twitter:title" content="ReCamMaster">
  <meta name="twitter:description" content="Recapture your videos with novel camera trajectories!">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="pics/icon.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>ReCamMaster: Camera-Controlled Generative Rendering from A Single Video</title>
  <link rel="icon" type="image/x-icon" href="pics/icon.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>

<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <img src="pics/icon.png" style="height:150px; margin-bottom: 20px; margin-top: -0px;"></img>
            <h1 class="title is-2 publication-title">ReCamMaster: Camera-Controlled Generative Rendering from A Single Video</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://jianhongbai.github.io/">Jianhong Bai</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://menghanxia.github.io/">Menghan Xia</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="https://fuxiao0719.github.io/">Xiao Fu</a><sup>3</sup>,</span>
              </span>
              <span class="author-block">
                <a href="https://xinntao.github.io/">Xintao Wang</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=dCik-2YAAAAJ&hl=en">Lianrui Mu</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://openreview.net/profile?id=~Jinwen_Cao1">Jinwen Cao</a><sup>2</sup>,
              </span>

              <br>
              <span class="author-block">
                <a href="https://person.zju.edu.cn/en/lzz">Zuozhu Liu</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://person.zju.edu.cn/en/huhaoji">Haoji Hu</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=UeltiQ4AAAAJ&hl=en">Xiang Bai</a><sup>4</sup>,
              </span>
              <span class="author-block">
                <a
                  href="https://scholar.google.com/citations?user=P6MraaYAAAAJ&hl=en">Pengfei Wan</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a
                  href="https://openreview.net/profile?id=~Di_ZHANG3">Di Zhang</a><sup>2</sup>
              </span>
            </div>
            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Zhejiang University,</span>&nbsp;
              <span class="author-block"><sup>2</sup>Kuaishou Technology,</span>&nbsp;
              <span class="author-block"><sup>3</sup>CUHK,</span>&nbsp;
              <span class="author-block"><sup>4</sup>HUST</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://drive.google.com/file/d/1UiJ8Yaf_GxvWvVZEmv9YaUDkKK8EaHQk/view?usp=sharing" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <!-- <span class="icon"> 
                      <i class="ai ai-arxiv"></i>
                    </span> -->
                    <span>Paper</span>
                  </a>
                </span>
                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon"> 
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>

                <!-- Github link -->
                <span class="link-block">
                  <a href="https://github.com/KwaiVGI/ReCamMaster" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Github (try ReCamMaster)</span>
                  </a>
                </span>

                <!-- Hugging Face Demo link with an image icon
                <span class="link-block">
                  <a href="https://huggingface.co/datasets/KwaiVGI/SynCamVideo-Dataset/" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <img src="pics/hf.png" alt="Dataset">
                    </span>
                    <span>Dataset</span>
                  </a>
                </span> -->

              </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  
  <section class="hero is-small" style="margin-top: -50px;">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-">
            <h2 class="subtitle has-text-justified">
              <b>TL;DR:</b> We propose ReCamMaster to re-capture in-the-wild videos with novel camera trajectories.
            </h2>
            <!-- <br> -->
            <div class="columns is-centered has-text-justified">
              <td colspan="3">
                <div style="text-align: center; width: 100%;">
                  <!-- <video muted autoplay="autoplay" loop="loop" width="100%" preload controls>
                    <source src="./videos/ReCamMaster/TEASER_compressed.mp4" type="video/mp4">
                  </video> -->
                  <!-- <video autoplay="autoplay" loop="loop" width="100%" preload controls>
                    <source src="./videos/ReCamMaster/TEASER_compressed.mp4" type="video/mp4">
                  </video> -->
                  <video muted autoplay="autoplay" loop="loop" width="100%" preload controls poster="./videos/ReCamMaster/TEASER.jpg">
                    <source src="./videos/ReCamMaster/TEASER_compressed.mp4" type="video/mp4">
                  </video>
                  <!-- <script>
                    document.addEventListener('DOMContentLoaded', (event) => {
                      var video = document.getElementById('videoPlayer');
                      video.volume = 0.5;
                    });
                  </script> -->
                  
                </div>
              </td>
            </div>

            <p><br></p>
  </section>



  <section class="hero is-small" style="margin-top: -50px;">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-">
            <br>
            <h2 class="title is-2">Demos</h2>
            <h1 class="title is-5 has-text-centered">Arc Trajectories</h1>
            <div class="columns is-centered has-text-justified">
              <td colspan="3">
                <div style="text-align: center; width: 100%;">
                  <div style="display: flex; justify-content: space-between; width: 90%; margin: 0 auto;">
                    <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<b>Source Videos</b></span>
                    <span><b>Synthesized Videos</b></span>
                    <span><b>Source Videos</b></span>
                    <span><b>Synthesized Videos</b>&nbsp;</span>
                  </div>
                  <video muted autoplay="autoplay" loop="loop" width="100%" preload controls poster="./videos/ReCamMaster/arc1_compressed.jpg">
                    <source src="./videos/ReCamMaster/arc1_compressed.mp4" type="video/mp4">
                  </video>
                </div>
              </td>
            </div>
            <p><br></p>
            <h1 class="title is-5 has-text-centered">Translation Up Trajectories</h1>
            <div class="columns is-centered has-text-justified">
              <td colspan="3">
                <div style="text-align: center; width: 100%;">
                  <div style="display: flex; justify-content: space-between; width: 90%; margin: 0 auto;">
                    <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<b>Source Videos</b></span>
                    <span><b>Synthesized Videos</b></span>
                    <span><b>Source Videos</b></span>
                    <span><b>Synthesized Videos</b>&nbsp;</span>
                  </div>
                <video muted autoplay="autoplay" loop="loop" width="100%" preload controls poster="./videos/ReCamMaster/translation up_compressed.jpg">
                  <source src="./videos/ReCamMaster/translation up_compressed.mp4" type="video/mp4">
                </video>
                </div>
              </td>
            </div>
            <p><br></p>
            <h1 class="title is-5 has-text-centered">Translation Down Trajectories</h1>
            <div class="columns is-centered has-text-justified">
              <td colspan="3">
                <div style="text-align: center; width: 100%;">
                  <div style="display: flex; justify-content: space-between; width: 90%; margin: 0 auto;">
                    <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<b>Source Videos</b></span>
                    <span><b>Synthesized Videos</b></span>
                    <span><b>Source Videos</b></span>
                    <span><b>Synthesized Videos</b>&nbsp;</span>
                  </div>
                <video muted autoplay="autoplay" loop="loop" width="100%" preload controls poster="./videos/ReCamMaster/translation down_compressed.jpg">
                  <source src="./videos/ReCamMaster/translation down_compressed.mp4" type="video/mp4">
                </video>
              </div>
              </td>
            </div>
            <p><br></p>
            <h1 class="title is-5 has-text-centered">Pan Trajectories</h1>
            <div class="columns is-centered has-text-justified">
              <td colspan="3">
                <div style="text-align: center; width: 100%;">
                  <div style="display: flex; justify-content: space-between; width: 90%; margin: 0 auto;">
                    <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<b>Source Videos</b></span>
                    <span><b>Synthesized Videos</b></span>
                    <span><b>Source Videos</b></span>
                    <span><b>Synthesized Videos</b>&nbsp;</span>
                  </div>
                <video muted autoplay="autoplay" loop="loop" width="100%" preload controls poster="./videos/ReCamMaster/pan_compressed.jpg">
                  <source src="./videos/ReCamMaster/pan_compressed.mp4" type="video/mp4">
                </video>
              </div>
              </td>
            </div>
            <p><br></p>
            <h1 class="title is-5 has-text-centered">Tilt Trajectories</h1>
            <div class="columns is-centered has-text-justified">
              <td colspan="3">
                <div style="text-align: center; width: 100%;">
                  <div style="display: flex; justify-content: space-between; width: 90%; margin: 0 auto;">
                    <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<b>Source Videos</b></span>
                    <span><b>Synthesized Videos</b></span>
                    <span><b>Source Videos</b></span>
                    <span><b>Synthesized Videos</b>&nbsp;</span>
                  </div>
                <video muted autoplay="autoplay" loop="loop" width="100%" preload controls poster="./videos/ReCamMaster/tilt_compressed.jpg">
                  <source src="./videos/ReCamMaster/tilt_compressed.mp4" type="video/mp4">
                </video>
              </div>
              </td>
            </div>
            <p><br></p>
            <h1 class="title is-5 has-text-centered">Zoom in / Zoom out Trajectories</h1>
            <div class="columns is-centered has-text-justified">
              <td colspan="3">
                <div style="text-align: center; width: 100%;">
                  <div style="display: flex; justify-content: space-between; width: 90%; margin: 0 auto;">
                    <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<b>Source Videos</b></span>
                    <span><b>Synthesized Videos</b></span>
                    <span><b>Source Videos</b></span>
                    <span><b>Synthesized Videos</b>&nbsp;</span>
                  </div>
                <video muted autoplay="autoplay" loop="loop" width="100%" preload controls poster="./videos/ReCamMaster/zoomin_zoomout_compressed.jpg">
                  <source src="./videos/ReCamMaster/zoomin_zoomout_compressed.mp4" type="video/mp4">
                </video>
              </div>
              </td>
            </div>
            <p><br></p>
            <h1 class="title is-5 has-text-centered">More Complex Trajectories</h1>
            <div class="columns is-centered has-text-justified">
              <td colspan="3">
                <div style="text-align: center; width: 100%;">
                  <div style="display: flex; justify-content: space-between; width: 75%; margin: 0 auto;">
                    <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<b>Source Videos</b></span>
                    <span><b>Synthesized Videos</b></span>
                    <span><b>Source Videos</b></span>
                    <span><b>Synthesized Videos</b>&nbsp;&nbsp;&nbsp;</span>
                  </div>
                <video muted autoplay="autoplay" loop="loop" width="100%" preload controls poster="./videos/ReCamMaster/random_traj_concat1_compressed.jpg">
                  <source src="./videos/ReCamMaster/random_traj_concat1_compressed.mp4" type="video/mp4">
                </video>
              </div>
              </td>
            </div>
            <p><br></p>
            <div class="columns is-centered has-text-justified">
              <td colspan="3">
                <div style="text-align: center; width: 100%;">
                  <div style="display: flex; justify-content: space-between; width: 75%; margin: 0 auto;">
                    <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<b>Source Videos</b></span>
                    <span><b>Synthesized Videos</b></span>
                    <span><b>Source Videos</b></span>
                    <span><b>Synthesized Videos</b>&nbsp;&nbsp;&nbsp;</span>
                  </div>
                <video muted autoplay="autoplay" loop="loop" width="100%" preload controls poster="./videos/ReCamMaster/random_traj_concat2_compressed.jpg">
                  <source src="./videos/ReCamMaster/random_traj_concat2_compressed.mp4">
                </video>
              </div>
              </td>
            </div>
            <p><br></p>
  </section>

  <br>
  <br>

  <section class="hero teaser is-light" style="margin-top: -50px;">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-">
            <br>
            <h2 class="title is-2">Application in 4D Reconstruction</h2>
            <div class="columns is-centered has-text-justified my_link">
              <!-- <td colspan="3">
                <p>
                  For amateur videographers or when shooting with a handheld camera, obtaining stable video is challenging. Video stabilization techniques aim to smooth out camera movements to produce easy-to-watch videos, which can be achieved by inputting smooth camera trajectories into ReCamMaster. To verify this, we used unsteady videos from the <a href="https://github.com/cxjyxxme/deep-online-video-stabilization-deploy">DeepStab</a> dataset (consisting of unsteady videos collected via handheld hardware) as input to the model and obtained stable videos as output. It can be observed that the model stabilizes the video while preserving the scenes and actions from the original video.
                </p>
                
              </td> -->
            </div>
            <br>
            <div class="columns is-centered has-text-justified">
              <td colspan="3">
                <div style="text-align: center; width: 100%;">
                  <div style="display: flex; justify-content: space-between; width: 90%; margin: 0 auto;">
                    <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<b>Source Videos</b></span>
                    <span><b>Synthesized Videos</b></span>
                    <span><b>Source Videos</b></span>
                    <span><b>Synthesized Videos</b>&nbsp;</span>
                  </div>
                <video muted autoplay="autoplay" loop="loop" width="100%" preload controls poster="./videos/ReCamMaster/4dtraj_compressed.jpg">
                  <source src="./videos/ReCamMaster/4dtraj_compressed.mp4" type="video/mp4">
                </video>
              </div>
              </td>
            </div>
            <p><br></p>
  </section>

  <section class="hero teaser is-light" style="margin-top: -50px;">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-">
            <br>
            <h2 class="title is-2">Application in Video Stabilization</h2>
            <div class="columns is-centered has-text-justified my_link">
              <td colspan="3">
                <p>
                  For amateur videographers or when shooting with a handheld camera, obtaining stable video is challenging. Video stabilization techniques aim to smooth out camera movements to produce easy-to-watch videos, which can be achieved by inputting smooth camera trajectories into ReCamMaster. To verify this, we used unsteady videos from the <a href="https://github.com/cxjyxxme/deep-online-video-stabilization-deploy">DeepStab</a> dataset (consisting of unsteady videos collected via handheld hardware) as input to the model and obtained stable videos as output. It can be observed that the model stabilizes the video while preserving the scenes and actions from the original video.
                </p>
                
              </td>
            </div>
            <br>
            <div class="columns is-centered has-text-justified">
              <td colspan="3">
                <div style="text-align: center; width: 100%;">
                  <div style="display: flex; justify-content: space-between; width: 90%; margin: 0 auto;">
                    <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<b>Source Videos</b></span>
                    <span><b>Synthesized Videos</b></span>
                    <span><b>Source Videos</b></span>
                    <span><b>Synthesized Videos</b>&nbsp;</span>
                  </div>
                <video muted autoplay="autoplay" loop="loop" width="100%" preload controls poster="./videos/ReCamMaster/stabilization_compressed.jpg">
                  <source src="./videos/ReCamMaster/stabilization_compressed.mp4" type="video/mp4">
                </video>
              </div>
              </td>
            </div>
            <p><br></p>
  </section>

  <section class="hero teaser is-light" style="margin-top: -50px;">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-">
            <br>
            <h2 class="title is-2">Application in Embodied AI</h2>
            <div class="columns is-centered has-text-justified my_link">
              <td colspan="3">
                <p>
                  In the realm of Embodied AI, creating large-scale, high-quality datasets like <a href="https://github.com/cxjyxxme/deep-online-video-stabilization-deploy">Bridge</a> or <a href="https://rail-berkeley.github.io/bridgedata/">AGIBOT</a> can be extremely expensive. ReCamMaster offers a solution by altering video perspectives, making it an effective tool for data augmentation. It could supply robots with multi-perspective observation data, thereby enhancing the performance of downstream tasks.
                </p>
                
              </td>
            </div>
            <br>
            <div class="columns is-centered has-text-justified">
              <td colspan="3">
                <div style="text-align: center; width: 100%;">
                  <div style="display: flex; justify-content: space-between; width: 90%; margin: 0 auto;">
                    <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<b>Source Videos</b></span>
                    <span><b>Synthesized Videos</b></span>
                    <span><b>Source Videos</b></span>
                    <span><b>Synthesized Videos</b>&nbsp;</span>
                  </div>
                <video muted autoplay="autoplay" loop="loop" width="100%" preload controls poster="./videos/ReCamMaster/embody_compressed.jpg">
                  <source src="./videos/ReCamMaster/embody_compressed.mp4" type="video/mp4">
                </video>
              </div>
              </td>
            </div>
            <p><br></p>
  </section>

  <section class="hero teaser is-light" style="margin-top: -50px;">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-">
            <br>
            <h2 class="title is-2">Application in Autonomous Driving</h2>
            <div class="columns is-centered has-text-justified my_link">
              <td colspan="3">
                <p>
                  We have discovered that ReCamMaster demonstrates promising generalization capabilities in autonomous driving scenarios. Consequently, it can serve as an effective data augmentation tool in autonomous driving.
                </p>
                
              </td>
            </div>
            <br>
            <div class="columns is-centered has-text-justified">
              <td colspan="3">
                <div style="text-align: center; width: 100%;">
                  <div style="display: flex; justify-content: space-between; width: 90%; margin: 0 auto;">
                    <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<b>Source Videos</b></span>
                    <span><b>Synthesized Videos</b></span>
                    <span><b>Source Videos</b></span>
                    <span><b>Synthesized Videos</b>&nbsp;</span>
                  </div>
                <video muted autoplay="autoplay" loop="loop" width="100%" preload controls poster="./videos/ReCamMaster/driving_compressed.jpg">
                  <source src="./videos/ReCamMaster/driving_compressed.mp4" type="video/mp4">
                </video>
              </div>
              </td>
            </div>
            <p><br></p>
  </section>

  <!-- Paper abstract -->
  <section class="section hero">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-2">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Camera control has been actively studied in text or image conditioned video generation tasks. However, altering camera trajectories of a given video remains under-explored, despite its importance in the field of video creation. This is non-trivial because it induces extra constraints of maintaining multiple-frame appearance and dynamic synchronization. To address this, we present ReCamMaster, a camera-controlled generative video re-rendering framework that reproduces the dynamic scene of an input video at novel camera trajectories. The core innovation lies in harnessing the generative capabilities of pre-trained text-to-video models through a thoroughly explored video conditioning mechanism. Considering the scarcity of qualified training data, we constructed a large-scale multi-camera synchronized video dataset using Unreal Engine 5, which is carefully curated to follow real-world filming characteristics, covering diverse scenes and camera movements. It helps the generalization of trained models to in-the-wild videos. Lastly, we further improve the robustness to diverse input through a meticulously designed training strategy. Extensive experiments tell that our method substantially outperforms existing state-of-the-art approaches and strong baselines. Our method also finds promising applications in video stabilization, super-resolution, and outpainting. Our code and dataset will be publicly available.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->



  <!-- Paper poster -->
  <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-">
            <h2 class="title is-2">Method</h2>
            <div class="content has-text-justified">
              <td colspan="3">
                <p>
                  To re-shoot a source video with novel camera trajectories, we propose to harness the generative capability of pre-trained text-to-video diffusion models by imposing dual conditions, i.e. the source video and target camera trajectories through a meticulously designed framework. The overview of the model is depicted below.
                </p>
              </td>
            </div>
            <div class="columns is-centered has-text-justified">
              <td colspan="3">
                <img src="pics/fig_pipe.png" width="100%" />
              </td>
            </div>
            <div class="content has-text-justified my_link">
              <td colspan="3">
                <p>
                  <i>Left:</i> The training pipeline of ReCamMaster. A latent diffusion model is optimized to reconstruct the target video <i>V<sub>t</sub> </i>, conditioned on the source video <i>V<sub>s</sub> </i>, target camera pose <i>cam<sub>t</sub> </i>, and target prompt <i>p<sub>t</sub> </i>. <i>Right:</i> Comparison of different video condition techniques. (a) Frame-dimension conditioning used in our paper; (b) Channel-dimension conditioning used in baseline methods <a href="#ref-gcd">[1]</a>, <a href="#ref-gs-dit">[2]</a>; (c) View-dimension conditioning in <a href="#ref-syncammaster">[3]</a>.
                </p>
              </td>
            </div>
            <p><br></p>
          </div>
  </section>
  <!--End paper poster -->


  <!-- Video grid single ref -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column custom-width">
            <h2 class="title is-2">Comparisons</h2>

            <div class="content has-text-justified my_link">
              <td colspan="3">
                <p>
                  We compare the proposed ReCamMaster with state-of-the-art camera-controlled video-to-video generation methods including GCD <a href="#ref-gcd">[1]</a>, Trajectory-Attention <a href="#ref-trajattn">[4]</a>, and DaS <a href="#ref-das">[5]</a>.
                </p>
                <!-- <p><br></p> -->
              </td>

            <div class="columns is-centered has-text-justified">
              <td colspan="3">
                <video muted autoplay="autoplay" loop="loop" width="100%" preload controls poster="./videos/comparison/compare with baseline_compressed.jpg">
                  <source src="./videos/comparison/compare with baseline_compressed.mp4" type="video/mp4">
                </video>
              </td>
            </div>
            <p><br></p>
        </div>
  </section>
  
  <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column custom-width">
            <h2 class="title is-2">Ablation on Video Conditioning Machanisms</h2>

            <div class="content has-text-justified my_link">
              <td colspan="3">
                <p>
                  In our paper, we propose a novel video conditioning scheme that concatenates the tokens of a source video with the target video tokens along the frame dimension. To verify the effectiveness, we compared the "channel concatenation" technique used in baseline methods <a href="#ref-gcd">[1]</a>, <a href="#ref-gs-dit">[2]</a> with the "view concatenation" technique from <a href="#ref-syncammaster">[3]</a>. It is evident that the designed conditioning technique significantly enhances the model's performance.
                </p>
                <!-- <p><br></p> -->
              </td>
              


            <div class="columns is-centered has-text-justified">
              <td colspan="3">
                <video muted autoplay="autoplay" loop="loop" width="100%" preload controls poster="./videos/ablation/ablation_on_video_conditioning_compressed.jpg">
                  <source src="./videos/ablation/ablation_on_video_conditioning_compressed.mp4" type="video/mp4">
                </video>
              </td>
            </div>
            <p><br></p>
        </div>
  </section>

  <section class="hero is-small">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column custom-width">
            <!-- <h2 class="title is-2"></h2> -->
            <div class="content has-text-justified" style="margin-top: -0px;">
              
              <b>Reference:</b> <br>
                <a name="ref-gcd" id="ref-gcd"></a>
                [1] Van Hoorick, Basile, et al. "Generative camera dolly: Extreme monocular dynamic novel view synthesis." European Conference on Computer Vision. Cham: Springer Nature Switzerland, 2024.<br>
                <a name="ref-gs-dit" id="ref-gs-dit"></a>
                [2] Bian, Weikang, et al. "GS-DiT: Advancing Video Generation with Pseudo 4D Gaussian Fields through Efficient Dense 3D Point Tracking." arXiv preprint arXiv:2501.02690 (2025).<br>
                <a name="ref-syncammaster" id="ref-syncammaster"></a>
                [3] Bai, Jianhong, et al. "SynCamMaster: Synchronizing Multi-Camera Video Generation from Diverse Viewpoints." arXiv preprint arXiv:2412.07760 (2024).<br>
                <a name="ref-trajattn" id="ref-trajattn"></a>
                [4] Zeqi Xiao, et al. "Trajectory attention for fine-grained video motion control." The Thirteenth International Conference on Learning Representations, 2025.<br>
                <a name="ref-das" id="ref-das"></a>
                [5] Gu, Zekai, et al. "Diffusion as Shader: 3D-aware Video Diffusion for Versatile Video Generation Control." arXiv preprint arXiv:2501.03847 (2025).<br>
                <br>
                <br>
            </div>
          </div>
        </div>
      </div>
    </section>
    <footer class="footer">
      <div class="container">
        <div class="columns is-centered">
          <div class="column is-8">
            <div class="content">

              <p>
                This page was built using the <a
                  href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic
                  Project Page Template</a> and <a href="https://diffusion-tokenflow.github.io/">TokenFlow</a>.
                <br> This website is licensed under a <a rel="license"
                  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                  Commons Attribution-ShareAlike 4.0 International License</a>.
              </p>

            </div>
          </div>
        </div>
      </div>
    </footer>

      <!-- Statcounter tracking code -->

      <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

      <!-- End of Statcounter Code -->
      <script>
        window.addEventListener('DOMContentLoaded', (event) => {
          const videoWrappers = document.querySelectorAll('.video-wrapper');

          videoWrappers.forEach(wrapper => {
            const defaultVideo = wrapper.querySelector('.default-video');
            const aspectRatio = defaultVideo.videoWidth / defaultVideo.videoHeight;
            const height = wrapper.offsetWidth / aspectRatio;

            wrapper.style.height = `${height}px`;

            wrapper.addEventListener('mouseenter', () => {
              defaultVideo.pause();
              hoverVideo.play();
            });

            wrapper.addEventListener('mouseleave', () => {
              defaultVideo.play();
              hoverVideo.pause();
            });
          });
        });
        $(document).ready(function () {
          var carouselItems = $('.carousel .item');
          var numItems = carouselItems.length;
          var numVideos = 5;
          var currentIndex = 0;

          $('.carousel').on('click', function () {
            currentIndex++;
            if (currentIndex + numVideos <= numItems) {
              carouselItems.removeClass('active');
              carouselItems.slice(currentIndex, currentIndex + numVideos).addClass('active');
            } else {
              currentIndex = 0;
              carouselItems.removeClass('active');
              carouselItems.slice(currentIndex, currentIndex + numVideos).addClass('active');
            }
          });

          carouselItems.slice(currentIndex, currentIndex + numVideos).addClass('active');
        });
      </script>
    </div>
  
</body>

</html>
